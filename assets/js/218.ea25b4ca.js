(window.webpackJsonp=window.webpackJsonp||[]).push([[218],{538:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"od-输出文件的八进制、十六进制等格式编码的字节"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#od-输出文件的八进制、十六进制等格式编码的字节"}},[t._v("#")]),t._v(" od - 输出文件的八进制、十六进制等格式编码的字节")]),t._v(" "),s("p",[t._v("将指定文件的内容以八进制、十进制、十六进制等编码方式显示。")]),t._v(" "),s("p",[t._v("od命令 用于输出文件的八进制、十六进制或其它格式编码的字节，通常用于显示或查看文件中不能直接显示在终端的字符。")]),t._v(" "),s("p",[t._v("常见的文件为文本文件和二进制文件。此命令主要用来查看保存在二进制文件中的值。比如，程序可能输出大量的数据记录，每个数据是一个单精度浮点数。这些数据记录存放在一个文件中，如果想查看下这个数据，这时候od命令就派上用场了。在我看来，od命令主要用来格式化输出文件数据，即对文件中的数据进行无二义性的解释。不管是IEEE754格式的浮点数还是ASCII码，od命令都能按照需求输出它们的值。")]),t._v(" "),s("h2",{attrs:{id:"适用范围"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#适用范围"}},[t._v("#")]),t._v(" 适用范围")]),t._v(" "),s("div",{staticClass:"svg redhat"},[t._v("RedHat")]),t._v(" "),s("div",{staticClass:"svg rhel"},[t._v("RHEL")]),t._v(" "),s("div",{staticClass:"svg ubuntu"},[t._v("Ubuntu")]),t._v(" "),s("div",{staticClass:"svg centos"},[t._v("CentOS")]),t._v(" "),s("div",{staticClass:"svg debian"},[t._v("Debian")]),t._v(" "),s("div",{staticClass:"svg deepin"},[t._v("Deepin")]),t._v(" "),s("div",{staticClass:"svg suse"},[t._v("SUSE")]),t._v(" "),s("div",{staticClass:"svg opensuse"},[t._v("openSUSE")]),t._v(" "),s("div",{staticClass:"svg fedora"},[t._v("Fedora")]),t._v(" "),s("div",{staticClass:"svg linuxmint"},[t._v("Linux Mint")]),t._v(" "),s("div",{staticClass:"svg alpinelinux"},[t._v("Alpine Linux")]),t._v(" "),s("div",{staticClass:"svg archlinux"},[t._v("Arch Linux")]),t._v(" "),s("h2",{attrs:{id:"语法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#语法"}},[t._v("#")]),t._v(" 语法")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("od  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("选项"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v("\nod  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("-abcdfilosx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v(". "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("+"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("OFFSET"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nod  "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("--traditional")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("OPTION"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v(". "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("FILE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("+"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("OFFSET"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("+"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("LABEL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("h2",{attrs:{id:"选项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#选项"}},[t._v("#")]),t._v(" 选项")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("-A, --address-radix"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("RADIX   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置偏移量的编码单位")]),t._v("\n-j, --skip-bytes"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BYTES      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 跳过指定书目的字符")]),t._v("\n-N, --read-bytes"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BYTES      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出指定字符数")]),t._v("\n-S, --strings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BYTES"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("       "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出至少BYTES个图形字符的字符串")]),t._v("\n-t, "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("--format")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("TYPE           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 指定输出格式")]),t._v("\n-w, --width"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("BYTES"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置每一行的最大字数")]),t._v("\n-v, --output-duplicates     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示重复的数据")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("--traditional")]),t._v("               "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 接受传统形式的参数")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("--help")]),t._v("                           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示帮助文档")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("--version")]),t._v("                        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示命令版本信息")]),t._v("\n")])])]),s("h2",{attrs:{id:"举例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#举例"}},[t._v("#")]),t._v(" 举例")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("cat")]),t._v(" test2.txt\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("212")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以八进制显示")]),t._v("\n0000000 031061 005063 031462 031012 031061 000012\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-t")]),t._v(" c test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以字符方式显示")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-b")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用单字节八进制解释进行输出，注意左侧的默认地址格式为八字节")]),t._v("\n0000000 061 062 063 012 062 063 012 062 061 062 012\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用ASCII码进行输出，注意其中包括转义字符")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-t")]),t._v(" d1 test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用单字节十进制进行解释")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("49")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("49")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-A")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置地址格式为十进制")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000011\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-A")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置地址格式为十六进制")]),t._v("\n000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n00000b\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-j")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 跳过开始的两个字节")]),t._v("\n0000002   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-N")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-j")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 跳过开始的两个字节，并且仅输出两个字节")]),t._v("\n0000002   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000004\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-w1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每行仅输出1个字节")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n0000001   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000002   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n0000003  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000004   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000005   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n0000006  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000007   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000010   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n0000011   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000012  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-w2")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每行仅输出2个字节")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000002   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000004   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n0000006  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000010   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n0000012  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ od "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-w3")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[t._v("-c")]),t._v(" test2.txt "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每行仅输出3个字节")]),t._v("\n0000000   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n0000003  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n0000006  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n0000011   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n\n0000013\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sogrey@bogon newDir3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ \n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);